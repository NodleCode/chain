<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="Source of the Rust file `&#x2F;home&#x2F;runner&#x2F;.cargo&#x2F;git&#x2F;checkouts&#x2F;polkadot-4038f27d5e4ea2e8&#x2F;7d8f00b&#x2F;node&#x2F;network&#x2F;protocol&#x2F;src&#x2F;request_response&#x2F;mod.rs`."><meta name="keywords" content="rust, rustlang, rust-lang"><title>mod.rs - source</title><link rel="stylesheet" type="text/css" href="../../../normalize.css"><link rel="stylesheet" type="text/css" href="../../../rustdoc.css" id="mainThemeStyle"><link rel="stylesheet" type="text/css" href="../../../light.css"  id="themeStyle"><link rel="stylesheet" type="text/css" href="../../../dark.css" disabled ><link rel="stylesheet" type="text/css" href="../../../ayu.css" disabled ><script id="default-settings" ></script><script src="../../../storage.js"></script><script src="../../../crates.js"></script><script defer src="../../../main.js"></script><script defer src="../../../source-script.js"></script><script defer src="../../../source-files.js"></script>
    <noscript><link rel="stylesheet" href="../../../noscript.css"></noscript><link rel="alternate icon" type="image/png" href="../../../favicon-16x16.png"><link rel="alternate icon" type="image/png" href="../../../favicon-32x32.png"><link rel="icon" type="image/svg+xml" href="../../../favicon.svg"><style type="text/css">#crate-search{background-image:url("../../../down-arrow.svg");}</style></head><body class="rustdoc source"><!--[if lte IE 11]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="sidebar"><div class="sidebar-menu" role="button">&#9776;</div><a href='../../../polkadot_node_network_protocol/index.html'><div class='logo-container rust-logo'><img src='../../../rust-logo.png' alt='logo'></div></a></nav><div class="theme-picker"><button id="theme-picker" aria-label="Pick another theme!" aria-haspopup="menu" title="themes"><img width="18" height="18" alt="Pick another theme!" src="../../../brush.svg"></button><div id="theme-choices" role="menu"></div></div><nav class="sub"><form class="search-form"><div class="search-container"><div><select id="crate-search"><option value="All crates">All crates</option></select><input class="search-input" name="search" autocomplete="off" spellcheck="false" placeholder="Click or press ‘S’ to search, ‘?’ for more options…" type="search"></div><button type="button" id="help-button" title="help">?</button><a id="settings-menu" href="../../../settings.html" title="settings"><img width="18" height="18" alt="Change settings" src="../../../wheel.svg"></a></div></form></nav><section id="main" class="content"><div class="example-wrap"><pre class="line-numbers"><span id="1">  1</span>
<span id="2">  2</span>
<span id="3">  3</span>
<span id="4">  4</span>
<span id="5">  5</span>
<span id="6">  6</span>
<span id="7">  7</span>
<span id="8">  8</span>
<span id="9">  9</span>
<span id="10"> 10</span>
<span id="11"> 11</span>
<span id="12"> 12</span>
<span id="13"> 13</span>
<span id="14"> 14</span>
<span id="15"> 15</span>
<span id="16"> 16</span>
<span id="17"> 17</span>
<span id="18"> 18</span>
<span id="19"> 19</span>
<span id="20"> 20</span>
<span id="21"> 21</span>
<span id="22"> 22</span>
<span id="23"> 23</span>
<span id="24"> 24</span>
<span id="25"> 25</span>
<span id="26"> 26</span>
<span id="27"> 27</span>
<span id="28"> 28</span>
<span id="29"> 29</span>
<span id="30"> 30</span>
<span id="31"> 31</span>
<span id="32"> 32</span>
<span id="33"> 33</span>
<span id="34"> 34</span>
<span id="35"> 35</span>
<span id="36"> 36</span>
<span id="37"> 37</span>
<span id="38"> 38</span>
<span id="39"> 39</span>
<span id="40"> 40</span>
<span id="41"> 41</span>
<span id="42"> 42</span>
<span id="43"> 43</span>
<span id="44"> 44</span>
<span id="45"> 45</span>
<span id="46"> 46</span>
<span id="47"> 47</span>
<span id="48"> 48</span>
<span id="49"> 49</span>
<span id="50"> 50</span>
<span id="51"> 51</span>
<span id="52"> 52</span>
<span id="53"> 53</span>
<span id="54"> 54</span>
<span id="55"> 55</span>
<span id="56"> 56</span>
<span id="57"> 57</span>
<span id="58"> 58</span>
<span id="59"> 59</span>
<span id="60"> 60</span>
<span id="61"> 61</span>
<span id="62"> 62</span>
<span id="63"> 63</span>
<span id="64"> 64</span>
<span id="65"> 65</span>
<span id="66"> 66</span>
<span id="67"> 67</span>
<span id="68"> 68</span>
<span id="69"> 69</span>
<span id="70"> 70</span>
<span id="71"> 71</span>
<span id="72"> 72</span>
<span id="73"> 73</span>
<span id="74"> 74</span>
<span id="75"> 75</span>
<span id="76"> 76</span>
<span id="77"> 77</span>
<span id="78"> 78</span>
<span id="79"> 79</span>
<span id="80"> 80</span>
<span id="81"> 81</span>
<span id="82"> 82</span>
<span id="83"> 83</span>
<span id="84"> 84</span>
<span id="85"> 85</span>
<span id="86"> 86</span>
<span id="87"> 87</span>
<span id="88"> 88</span>
<span id="89"> 89</span>
<span id="90"> 90</span>
<span id="91"> 91</span>
<span id="92"> 92</span>
<span id="93"> 93</span>
<span id="94"> 94</span>
<span id="95"> 95</span>
<span id="96"> 96</span>
<span id="97"> 97</span>
<span id="98"> 98</span>
<span id="99"> 99</span>
<span id="100">100</span>
<span id="101">101</span>
<span id="102">102</span>
<span id="103">103</span>
<span id="104">104</span>
<span id="105">105</span>
<span id="106">106</span>
<span id="107">107</span>
<span id="108">108</span>
<span id="109">109</span>
<span id="110">110</span>
<span id="111">111</span>
<span id="112">112</span>
<span id="113">113</span>
<span id="114">114</span>
<span id="115">115</span>
<span id="116">116</span>
<span id="117">117</span>
<span id="118">118</span>
<span id="119">119</span>
<span id="120">120</span>
<span id="121">121</span>
<span id="122">122</span>
<span id="123">123</span>
<span id="124">124</span>
<span id="125">125</span>
<span id="126">126</span>
<span id="127">127</span>
<span id="128">128</span>
<span id="129">129</span>
<span id="130">130</span>
<span id="131">131</span>
<span id="132">132</span>
<span id="133">133</span>
<span id="134">134</span>
<span id="135">135</span>
<span id="136">136</span>
<span id="137">137</span>
<span id="138">138</span>
<span id="139">139</span>
<span id="140">140</span>
<span id="141">141</span>
<span id="142">142</span>
<span id="143">143</span>
<span id="144">144</span>
<span id="145">145</span>
<span id="146">146</span>
<span id="147">147</span>
<span id="148">148</span>
<span id="149">149</span>
<span id="150">150</span>
<span id="151">151</span>
<span id="152">152</span>
<span id="153">153</span>
<span id="154">154</span>
<span id="155">155</span>
<span id="156">156</span>
<span id="157">157</span>
<span id="158">158</span>
<span id="159">159</span>
<span id="160">160</span>
<span id="161">161</span>
<span id="162">162</span>
<span id="163">163</span>
<span id="164">164</span>
<span id="165">165</span>
<span id="166">166</span>
<span id="167">167</span>
<span id="168">168</span>
<span id="169">169</span>
<span id="170">170</span>
<span id="171">171</span>
<span id="172">172</span>
<span id="173">173</span>
<span id="174">174</span>
<span id="175">175</span>
<span id="176">176</span>
<span id="177">177</span>
<span id="178">178</span>
<span id="179">179</span>
<span id="180">180</span>
<span id="181">181</span>
<span id="182">182</span>
<span id="183">183</span>
<span id="184">184</span>
<span id="185">185</span>
<span id="186">186</span>
<span id="187">187</span>
<span id="188">188</span>
<span id="189">189</span>
<span id="190">190</span>
<span id="191">191</span>
<span id="192">192</span>
<span id="193">193</span>
<span id="194">194</span>
<span id="195">195</span>
<span id="196">196</span>
<span id="197">197</span>
<span id="198">198</span>
<span id="199">199</span>
<span id="200">200</span>
<span id="201">201</span>
<span id="202">202</span>
<span id="203">203</span>
<span id="204">204</span>
<span id="205">205</span>
<span id="206">206</span>
<span id="207">207</span>
<span id="208">208</span>
<span id="209">209</span>
<span id="210">210</span>
<span id="211">211</span>
<span id="212">212</span>
<span id="213">213</span>
<span id="214">214</span>
<span id="215">215</span>
<span id="216">216</span>
<span id="217">217</span>
<span id="218">218</span>
<span id="219">219</span>
<span id="220">220</span>
<span id="221">221</span>
<span id="222">222</span>
<span id="223">223</span>
<span id="224">224</span>
<span id="225">225</span>
<span id="226">226</span>
<span id="227">227</span>
<span id="228">228</span>
<span id="229">229</span>
<span id="230">230</span>
<span id="231">231</span>
<span id="232">232</span>
<span id="233">233</span>
<span id="234">234</span>
<span id="235">235</span>
<span id="236">236</span>
<span id="237">237</span>
<span id="238">238</span>
<span id="239">239</span>
<span id="240">240</span>
<span id="241">241</span>
<span id="242">242</span>
<span id="243">243</span>
<span id="244">244</span>
<span id="245">245</span>
<span id="246">246</span>
<span id="247">247</span>
<span id="248">248</span>
<span id="249">249</span>
<span id="250">250</span>
<span id="251">251</span>
<span id="252">252</span>
<span id="253">253</span>
<span id="254">254</span>
<span id="255">255</span>
<span id="256">256</span>
<span id="257">257</span>
<span id="258">258</span>
<span id="259">259</span>
<span id="260">260</span>
<span id="261">261</span>
<span id="262">262</span>
<span id="263">263</span>
<span id="264">264</span>
<span id="265">265</span>
</pre><pre class="rust"><code><span class="comment">// Copyright 2021 Parity Technologies (UK) Ltd.</span>
<span class="comment">// This file is part of Polkadot.</span>

<span class="comment">// Polkadot is free software: you can redistribute it and/or modify</span>
<span class="comment">// it under the terms of the GNU General Public License as published by</span>
<span class="comment">// the Free Software Foundation, either version 3 of the License, or</span>
<span class="comment">// (at your option) any later version.</span>

<span class="comment">// Polkadot is distributed in the hope that it will be useful,</span>
<span class="comment">// but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="comment">// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="comment">// GNU General Public License for more details.</span>

<span class="comment">// You should have received a copy of the GNU General Public License</span>
<span class="comment">// along with Polkadot.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>

<span class="doccomment">//! Overview over request/responses as used in `Polkadot`.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! `enum Protocol` .... List of all supported protocols.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! `enum Requests`  .... List of all supported requests, each entry matches one in protocols, but</span>
<span class="doccomment">//! has the actual request as payload.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! `struct IncomingRequest` .... wrapper for incoming requests, containing a sender for sending</span>
<span class="doccomment">//! responses.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! `struct OutgoingRequest` .... wrapper for outgoing requests, containing a sender used by the</span>
<span class="doccomment">//! networking code for delivering responses/delivery errors.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! `trait IsRequest` .... A trait describing a particular request. It is used for gathering meta</span>
<span class="doccomment">//! data, like what is the corresponding response type.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//!  Versioned (v1 module): The actual requests and responses as sent over the network.</span>

<span class="kw">use</span> <span class="ident">std</span>::{<span class="ident">borrow::Cow</span>, <span class="ident">time::Duration</span>, <span class="ident">u64</span>};

<span class="kw">use</span> <span class="ident">futures::channel::mpsc</span>;
<span class="kw">use</span> <span class="ident">polkadot_primitives::v1</span>::{<span class="ident">MAX_CODE_SIZE</span>, <span class="ident">MAX_POV_SIZE</span>};
<span class="kw">use</span> <span class="ident">strum::EnumIter</span>;

<span class="kw">pub</span> <span class="kw">use</span> <span class="ident">sc_network</span>::{<span class="ident">config</span> <span class="kw">as</span> <span class="ident">network</span>, <span class="ident">config::RequestResponseConfig</span>};

<span class="doccomment">/// Everything related to handling of incoming requests.</span>
<span class="kw">pub</span> <span class="kw">mod</span> <span class="ident">incoming</span>;
<span class="doccomment">/// Everything related to handling of outgoing requests.</span>
<span class="kw">pub</span> <span class="kw">mod</span> <span class="ident">outgoing</span>;

<span class="kw">pub</span> <span class="kw">use</span> <span class="ident">incoming</span>::{<span class="ident">IncomingRequest</span>, <span class="ident">IncomingRequestReceiver</span>};

<span class="kw">pub</span> <span class="kw">use</span> <span class="ident">outgoing</span>::{<span class="ident">OutgoingRequest</span>, <span class="ident">OutgoingResult</span>, <span class="ident">Recipient</span>, <span class="ident">Requests</span>, <span class="ident">ResponseSender</span>};

<span class="comment">///// Multiplexer for incoming requests.</span>
<span class="comment">// pub mod multiplexer;</span>

<span class="doccomment">/// Actual versioned requests and responses, that are sent over the wire.</span>
<span class="kw">pub</span> <span class="kw">mod</span> <span class="ident">v1</span>;

<span class="doccomment">/// A protocol per subsystem seems to make the most sense, this way we don&#39;t need any dispatching</span>
<span class="doccomment">/// within protocols.</span>
<span class="attribute">#[<span class="ident">derive</span>(<span class="ident">Copy</span>, <span class="ident">Clone</span>, <span class="ident">Debug</span>, <span class="ident">Hash</span>, <span class="ident">PartialEq</span>, <span class="ident">Eq</span>, <span class="ident">EnumIter</span>)]</span>
<span class="kw">pub</span> <span class="kw">enum</span> <span class="ident">Protocol</span> {
	<span class="doccomment">/// Protocol for chunk fetching, used by availability distribution and availability recovery.</span>
	<span class="ident">ChunkFetching</span>,
	<span class="doccomment">/// Protocol for fetching collations from collators.</span>
	<span class="ident">CollationFetching</span>,
	<span class="doccomment">/// Protocol for fetching seconded PoVs from validators of the same group.</span>
	<span class="ident">PoVFetching</span>,
	<span class="doccomment">/// Protocol for fetching available data.</span>
	<span class="ident">AvailableDataFetching</span>,
	<span class="doccomment">/// Fetching of statements that are too large for gossip.</span>
	<span class="ident">StatementFetching</span>,
	<span class="doccomment">/// Sending of dispute statements with application level confirmations.</span>
	<span class="ident">DisputeSending</span>,
}

<span class="doccomment">/// Minimum bandwidth we expect for validators - 500Mbit/s is the recommendation, so approximately</span>
<span class="doccomment">/// 50MB per second:</span>
<span class="kw">const</span> <span class="ident">MIN_BANDWIDTH_BYTES</span>: <span class="ident">u64</span> <span class="op">=</span> <span class="number">50</span> <span class="op">*</span> <span class="number">1024</span> <span class="op">*</span> <span class="number">1024</span>;

<span class="doccomment">/// Default request timeout in seconds.</span>
<span class="doccomment">///</span>
<span class="doccomment">/// When decreasing this value, take into account that the very first request might need to open a</span>
<span class="doccomment">/// connection, which can be slow. If this causes problems, we should ensure connectivity via peer</span>
<span class="doccomment">/// sets.</span>
<span class="attribute">#[<span class="ident">allow</span>(<span class="ident">dead_code</span>)]</span>
<span class="kw">const</span> <span class="ident">DEFAULT_REQUEST_TIMEOUT</span>: <span class="ident">Duration</span> <span class="op">=</span> <span class="ident">Duration::from_secs</span>(<span class="number">3</span>);

<span class="doccomment">/// Request timeout where we can assume the connection is already open (e.g. we have peers in a</span>
<span class="doccomment">/// peer set as well).</span>
<span class="kw">const</span> <span class="ident">DEFAULT_REQUEST_TIMEOUT_CONNECTED</span>: <span class="ident">Duration</span> <span class="op">=</span> <span class="ident">Duration::from_secs</span>(<span class="number">1</span>);

<span class="doccomment">/// Timeout for requesting availability chunks.</span>
<span class="kw">pub</span> <span class="kw">const</span> <span class="ident">CHUNK_REQUEST_TIMEOUT</span>: <span class="ident">Duration</span> <span class="op">=</span> <span class="ident">DEFAULT_REQUEST_TIMEOUT_CONNECTED</span>;

<span class="doccomment">/// This timeout is based on what seems sensible from a time budget perspective, considering 6</span>
<span class="doccomment">/// second block time. This is going to be tough, if we have multiple forks and large PoVs, but we</span>
<span class="doccomment">/// only have so much time.</span>
<span class="kw">const</span> <span class="ident">POV_REQUEST_TIMEOUT_CONNECTED</span>: <span class="ident">Duration</span> <span class="op">=</span> <span class="ident">Duration::from_millis</span>(<span class="number">1000</span>);

<span class="doccomment">/// We want timeout statement requests fast, so we don&#39;t waste time on slow nodes. Responders will</span>
<span class="doccomment">/// try their best to either serve within that timeout or return an error immediately. (We need to</span>
<span class="doccomment">/// fit statement distribution within a block of 6 seconds.)</span>
<span class="kw">const</span> <span class="ident">STATEMENTS_TIMEOUT</span>: <span class="ident">Duration</span> <span class="op">=</span> <span class="ident">Duration::from_secs</span>(<span class="number">1</span>);

<span class="doccomment">/// We don&#39;t want a slow peer to slow down all the others, at the same time we want to get out the</span>
<span class="doccomment">/// data quickly in full to at least some peers (as this will reduce load on us as they then can</span>
<span class="doccomment">/// start serving the data). So this value is a tradeoff. 3 seems to be sensible. So we would need</span>
<span class="doccomment">/// to have 3 slow nodes connected, to delay transfer for others by `STATEMENTS_TIMEOUT`.</span>
<span class="kw">pub</span> <span class="kw">const</span> <span class="ident">MAX_PARALLEL_STATEMENT_REQUESTS</span>: <span class="ident">u32</span> <span class="op">=</span> <span class="number">3</span>;

<span class="doccomment">/// Response size limit for responses of POV like data.</span>
<span class="doccomment">///</span>
<span class="doccomment">/// This is larger than `MAX_POV_SIZE` to account for protocol overhead and for additional data in</span>
<span class="doccomment">/// `CollationFetching` or `AvailableDataFetching` for example. We try to err on larger limits here</span>
<span class="doccomment">/// as a too large limit only allows an attacker to waste our bandwidth some more, a too low limit</span>
<span class="doccomment">/// might have more severe effects.</span>
<span class="kw">const</span> <span class="ident">POV_RESPONSE_SIZE</span>: <span class="ident">u64</span> <span class="op">=</span> <span class="ident">MAX_POV_SIZE</span> <span class="kw">as</span> <span class="ident">u64</span> <span class="op">+</span> <span class="number">10_000</span>;

<span class="doccomment">/// Maximum response sizes for `StatementFetching`.</span>
<span class="doccomment">///</span>
<span class="doccomment">/// This is `MAX_CODE_SIZE` plus some additional space for protocol overhead.</span>
<span class="kw">const</span> <span class="ident">STATEMENT_RESPONSE_SIZE</span>: <span class="ident">u64</span> <span class="op">=</span> <span class="ident">MAX_CODE_SIZE</span> <span class="kw">as</span> <span class="ident">u64</span> <span class="op">+</span> <span class="number">10_000</span>;

<span class="kw">impl</span> <span class="ident">Protocol</span> {
	<span class="doccomment">/// Get a configuration for a given Request response protocol.</span>
	<span class="doccomment">///</span>
	<span class="doccomment">/// Returns a receiver for messages received on this protocol and the requested</span>
	<span class="doccomment">/// `ProtocolConfig`.</span>
	<span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">get_config</span>(<span class="self">self</span>) -&gt; (<span class="ident">mpsc::Receiver</span><span class="op">&lt;</span><span class="ident">network::IncomingRequest</span><span class="op">&gt;</span>, <span class="ident">RequestResponseConfig</span>) {
		<span class="kw">let</span> <span class="ident">p_name</span> <span class="op">=</span> <span class="self">self</span>.<span class="ident">into_protocol_name</span>();
		<span class="kw">let</span> (<span class="ident">tx</span>, <span class="ident">rx</span>) <span class="op">=</span> <span class="ident">mpsc::channel</span>(<span class="self">self</span>.<span class="ident">get_channel_size</span>());
		<span class="kw">let</span> <span class="ident">cfg</span> <span class="op">=</span> <span class="kw">match</span> <span class="self">self</span> {
			<span class="ident">Protocol::ChunkFetching</span> =&gt; <span class="ident">RequestResponseConfig</span> {
				<span class="ident">name</span>: <span class="ident">p_name</span>,
				<span class="ident">max_request_size</span>: <span class="number">1_000</span>,
				<span class="ident">max_response_size</span>: <span class="ident">POV_RESPONSE_SIZE</span> <span class="kw">as</span> <span class="ident">u64</span> <span class="op">*</span> <span class="number">3</span>,
				<span class="comment">// We are connected to all validators:</span>
				<span class="ident">request_timeout</span>: <span class="ident">CHUNK_REQUEST_TIMEOUT</span>,
				<span class="ident">inbound_queue</span>: <span class="prelude-val">Some</span>(<span class="ident">tx</span>),
			},
			<span class="ident">Protocol::CollationFetching</span> =&gt; <span class="ident">RequestResponseConfig</span> {
				<span class="ident">name</span>: <span class="ident">p_name</span>,
				<span class="ident">max_request_size</span>: <span class="number">1_000</span>,
				<span class="ident">max_response_size</span>: <span class="ident">POV_RESPONSE_SIZE</span>,
				<span class="comment">// Taken from initial implementation in collator protocol:</span>
				<span class="ident">request_timeout</span>: <span class="ident">POV_REQUEST_TIMEOUT_CONNECTED</span>,
				<span class="ident">inbound_queue</span>: <span class="prelude-val">Some</span>(<span class="ident">tx</span>),
			},
			<span class="ident">Protocol::PoVFetching</span> =&gt; <span class="ident">RequestResponseConfig</span> {
				<span class="ident">name</span>: <span class="ident">p_name</span>,
				<span class="ident">max_request_size</span>: <span class="number">1_000</span>,
				<span class="ident">max_response_size</span>: <span class="ident">POV_RESPONSE_SIZE</span>,
				<span class="ident">request_timeout</span>: <span class="ident">POV_REQUEST_TIMEOUT_CONNECTED</span>,
				<span class="ident">inbound_queue</span>: <span class="prelude-val">Some</span>(<span class="ident">tx</span>),
			},
			<span class="ident">Protocol::AvailableDataFetching</span> =&gt; <span class="ident">RequestResponseConfig</span> {
				<span class="ident">name</span>: <span class="ident">p_name</span>,
				<span class="ident">max_request_size</span>: <span class="number">1_000</span>,
				<span class="comment">// Available data size is dominated by the PoV size.</span>
				<span class="ident">max_response_size</span>: <span class="ident">POV_RESPONSE_SIZE</span>,
				<span class="ident">request_timeout</span>: <span class="ident">POV_REQUEST_TIMEOUT_CONNECTED</span>,
				<span class="ident">inbound_queue</span>: <span class="prelude-val">Some</span>(<span class="ident">tx</span>),
			},
			<span class="ident">Protocol::StatementFetching</span> =&gt; <span class="ident">RequestResponseConfig</span> {
				<span class="ident">name</span>: <span class="ident">p_name</span>,
				<span class="ident">max_request_size</span>: <span class="number">1_000</span>,
				<span class="comment">// Available data size is dominated code size.</span>
				<span class="ident">max_response_size</span>: <span class="ident">STATEMENT_RESPONSE_SIZE</span>,
				<span class="comment">// We need statement fetching to be fast and will try our best at the responding</span>
				<span class="comment">// side to answer requests within that timeout, assuming a bandwidth of 500Mbit/s</span>
				<span class="comment">// - which is the recommended minimum bandwidth for nodes on Kusama as of April</span>
				<span class="comment">// 2021.</span>
				<span class="comment">// Responders will reject requests, if it is unlikely they can serve them within</span>
				<span class="comment">// the timeout, so the requester can immediately try another node, instead of</span>
				<span class="comment">// waiting for timeout on an overloaded node.  Fetches from slow nodes will likely</span>
				<span class="comment">// fail, but this is desired, so we can quickly move on to a faster one - we should</span>
				<span class="comment">// also decrease its reputation.</span>
				<span class="ident">request_timeout</span>: <span class="ident">Duration::from_secs</span>(<span class="number">1</span>),
				<span class="ident">inbound_queue</span>: <span class="prelude-val">Some</span>(<span class="ident">tx</span>),
			},
			<span class="ident">Protocol::DisputeSending</span> =&gt; <span class="ident">RequestResponseConfig</span> {
				<span class="ident">name</span>: <span class="ident">p_name</span>,
				<span class="ident">max_request_size</span>: <span class="number">1_000</span>,
				<span class="doccomment">/// Responses are just confirmation, in essence not even a bit. So 100 seems</span>
				<span class="doccomment">/// plenty.</span>
				<span class="ident">max_response_size</span>: <span class="number">100</span>,
				<span class="doccomment">/// We can have relative large timeouts here, there is no value of hitting a</span>
				<span class="doccomment">/// timeout as we want to get statements through to each node in any case.</span>
				<span class="ident">request_timeout</span>: <span class="ident">Duration::from_secs</span>(<span class="number">12</span>),
				<span class="ident">inbound_queue</span>: <span class="prelude-val">Some</span>(<span class="ident">tx</span>),
			},
		};
		(<span class="ident">rx</span>, <span class="ident">cfg</span>)
	}

	<span class="comment">// Channel sizes for the supported protocols.</span>
	<span class="kw">fn</span> <span class="ident">get_channel_size</span>(<span class="self">self</span>) -&gt; <span class="ident">usize</span> {
		<span class="kw">match</span> <span class="self">self</span> {
			<span class="comment">// Hundreds of validators will start requesting their chunks once they see a candidate</span>
			<span class="comment">// awaiting availability on chain. Given that they will see that block at different</span>
			<span class="comment">// times (due to network delays), 100 seems big enough to accomodate for &quot;bursts&quot;,</span>
			<span class="comment">// assuming we can service requests relatively quickly, which would need to be measured</span>
			<span class="comment">// as well.</span>
			<span class="ident">Protocol::ChunkFetching</span> =&gt; <span class="number">100</span>,
			<span class="comment">// 10 seems reasonable, considering group sizes of max 10 validators.</span>
			<span class="ident">Protocol::CollationFetching</span> =&gt; <span class="number">10</span>,
			<span class="comment">// 10 seems reasonable, considering group sizes of max 10 validators.</span>
			<span class="ident">Protocol::PoVFetching</span> =&gt; <span class="number">10</span>,
			<span class="comment">// Validators are constantly self-selecting to request available data which may lead</span>
			<span class="comment">// to constant load and occasional burstiness.</span>
			<span class="ident">Protocol::AvailableDataFetching</span> =&gt; <span class="number">100</span>,
			<span class="comment">// Our queue size approximation is how many blocks of the size of</span>
			<span class="comment">// a runtime we can transfer within a statements timeout, minus the requests we handle</span>
			<span class="comment">// in parallel.</span>
			<span class="ident">Protocol::StatementFetching</span> =&gt; {
				<span class="comment">// We assume we can utilize up to 70% of the available bandwidth for statements.</span>
				<span class="comment">// This is just a guess/estimate, with the following considerations: If we are</span>
				<span class="comment">// faster than that, queue size will stay low anyway, even if not - requesters will</span>
				<span class="comment">// get an immediate error, but if we are slower, requesters will run in a timeout -</span>
				<span class="comment">// wasting precious time.</span>
				<span class="kw">let</span> <span class="ident">available_bandwidth</span> <span class="op">=</span> <span class="number">7</span> <span class="op">*</span> <span class="ident">MIN_BANDWIDTH_BYTES</span> <span class="op">/</span> <span class="number">10</span>;
				<span class="kw">let</span> <span class="ident">size</span> <span class="op">=</span> <span class="ident">u64::saturating_sub</span>(
					<span class="ident">STATEMENTS_TIMEOUT</span>.<span class="ident">as_millis</span>() <span class="kw">as</span> <span class="ident">u64</span> <span class="op">*</span> <span class="ident">available_bandwidth</span> <span class="op">/</span>
						(<span class="number">1000</span> <span class="op">*</span> <span class="ident">MAX_CODE_SIZE</span> <span class="kw">as</span> <span class="ident">u64</span>),
					<span class="ident">MAX_PARALLEL_STATEMENT_REQUESTS</span> <span class="kw">as</span> <span class="ident">u64</span>,
				);
				<span class="macro">debug_assert!</span>(
					<span class="ident">size</span> <span class="op">&gt;</span> <span class="number">0</span>,
					<span class="string">&quot;We should have a channel size greater zero, otherwise we won&#39;t accept any requests.&quot;</span>
				);
				<span class="ident">size</span> <span class="kw">as</span> <span class="ident">usize</span>
			},
			<span class="comment">// Incoming requests can get bursty, we should also be able to handle them fast on</span>
			<span class="comment">// average, so something in the ballpark of 100 should be fine. Nodes will retry on</span>
			<span class="comment">// failure, so having a good value here is mostly about performance tuning.</span>
			<span class="ident">Protocol::DisputeSending</span> =&gt; <span class="number">100</span>,
		}
	}

	<span class="doccomment">/// Get the protocol name of this protocol, as understood by substrate networking.</span>
	<span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">into_protocol_name</span>(<span class="self">self</span>) -&gt; <span class="ident">Cow</span><span class="op">&lt;</span><span class="lifetime">&#39;static</span>, <span class="ident">str</span><span class="op">&gt;</span> {
		<span class="self">self</span>.<span class="ident">get_protocol_name_static</span>().<span class="ident">into</span>()
	}

	<span class="doccomment">/// Get the protocol name associated with each peer set as static str.</span>
	<span class="kw">pub</span> <span class="kw">const</span> <span class="kw">fn</span> <span class="ident">get_protocol_name_static</span>(<span class="self">self</span>) -&gt; <span class="kw-2">&amp;</span><span class="lifetime">&#39;static</span> <span class="ident">str</span> {
		<span class="kw">match</span> <span class="self">self</span> {
			<span class="ident">Protocol::ChunkFetching</span> =&gt; <span class="string">&quot;/polkadot/req_chunk/1&quot;</span>,
			<span class="ident">Protocol::CollationFetching</span> =&gt; <span class="string">&quot;/polkadot/req_collation/1&quot;</span>,
			<span class="ident">Protocol::PoVFetching</span> =&gt; <span class="string">&quot;/polkadot/req_pov/1&quot;</span>,
			<span class="ident">Protocol::AvailableDataFetching</span> =&gt; <span class="string">&quot;/polkadot/req_available_data/1&quot;</span>,
			<span class="ident">Protocol::StatementFetching</span> =&gt; <span class="string">&quot;/polkadot/req_statement/1&quot;</span>,
			<span class="ident">Protocol::DisputeSending</span> =&gt; <span class="string">&quot;/polkadot/send_dispute/1&quot;</span>,
		}
	}
}

<span class="doccomment">/// Common properties of any `Request`.</span>
<span class="kw">pub</span> <span class="kw">trait</span> <span class="ident">IsRequest</span> {
	<span class="doccomment">/// Each request has a corresponding `Response`.</span>
	<span class="kw">type</span> <span class="ident">Response</span>;

	<span class="doccomment">/// What protocol this `Request` implements.</span>
	<span class="kw">const</span> <span class="ident">PROTOCOL</span>: <span class="ident">Protocol</span>;
}
</code></pre></div>
</section><section id="search" class="content hidden"></section><div id="rustdoc-vars" data-root-path="../../../" data-current-crate="polkadot_node_network_protocol" data-search-index-js="../../../search-index.js" data-search-js="../../../search.js"></div>
</body></html>